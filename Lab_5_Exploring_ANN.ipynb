{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "sgYKWieNKq1m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k45Bn0b8Rx_y"
      },
      "source": [
        "#Here, I have import the dataseet from Tensorflow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyNhyH2oMAw6"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "NwgfF4hwLRl-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train_flat, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0d2tZ6RKmj"
      },
      "source": [
        "#ANN Implementation from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ruWm4uO1QNr1"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.b1 = np.zeros((1, self.hidden_size))\n",
        "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.b2 = np.zeros((1, self.output_size))\n",
        "# active\n",
        "    def relu(self, z):\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "    def softmax(self, z):\n",
        "        exp_scores = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        exp_scores = np.exp(self.z2)\n",
        "        self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "        return self.probs\n",
        "    def backward(self, X, y, learning_rate, reg_lambda):\n",
        "    # def backward(self, X, y, learning_rate):\n",
        "        num_examples = X.shape[0]\n",
        "  # error\n",
        "        delta3 = self.probs\n",
        "        delta3[range(num_examples), y] -= 1\n",
        "  #  lossFun hid\n",
        "        dW2 = np.dot(self.a1.T, delta3)\n",
        "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
        "        delta2 = np.dot(delta3, self.W2.T) * (self.a1 * (1 - self.a1))\n",
        "  # loss inp\n",
        "        dW1 = np.dot(X.T, delta2)\n",
        "        db1 = np.sum(delta2, axis=0)\n",
        "        # Regularization terms\n",
        "        dW2 += reg_lambda * self.W2\n",
        "        dW1 += reg_lambda * self.W1\n",
        "# update\n",
        "        self.W1 -= learning_rate * dW1\n",
        "        self.b1 -= learning_rate * db1\n",
        "        self.W2 -= learning_rate * dW2\n",
        "        self.b2 -= learning_rate * db2\n",
        "\n",
        "    def fit(self, X, y, learning_rate=0.01, reg_lambda=0.01, epochs=1000, batch_size=32):\n",
        "        for i in range(epochs):\n",
        "            # Mini-batch SGD\n",
        "            for j in range(0, X.shape[0], batch_size):\n",
        "                X_batch = X[j:j+batch_size]\n",
        "                y_batch = y[j:j+batch_size]\n",
        "                self.forward(X_batch)\n",
        "                self.backward(X_batch, y_batch, learning_rate, reg_lambda)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.forward(X), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn1kK_LsRgaL"
      },
      "source": [
        "#ANN using Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4bTr4VUROWu",
        "outputId": "4abae869-fc60-421a-a03a-fe708fdac6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2880 - accuracy: 0.9177 - val_loss: 0.1683 - val_accuracy: 0.9525\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1283 - accuracy: 0.9626 - val_loss: 0.1213 - val_accuracy: 0.9658\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0869 - accuracy: 0.9745 - val_loss: 0.0965 - val_accuracy: 0.9707\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0654 - accuracy: 0.9796 - val_loss: 0.0952 - val_accuracy: 0.9719\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.0915 - val_accuracy: 0.9741\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.1012 - val_accuracy: 0.9714\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.0890 - val_accuracy: 0.9746\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.0919 - val_accuracy: 0.9743\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0939 - val_accuracy: 0.9753\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.1041 - val_accuracy: 0.9707\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train_split, y_train_split, epochs=10, validation_data=(x_val_split, y_val_split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvVuGR-aRiP9",
        "outputId": "763c361d-d3aa-48a4-c873-9253bd1395b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1095 - accuracy: 0.9680\n",
            "Custom ANN Accuracy: 97.06\n"
          ]
        }
      ],
      "source": [
        "# Instantiate custom ANN\n",
        "custom_ann = NeuralNetwork(input_size=784, hidden_size=128, output_size=10)\n",
        "\n",
        "# Fit custom ANN\n",
        "custom_ann.fit(x_train_split, y_train_split, learning_rate=0.01, reg_lambda=0.01, epochs=100, batch_size=32)\n",
        "\n",
        "# Evaluate custom ANN\n",
        "custom_ann_accuracy = np.mean(custom_ann.predict(x_test_flat) == y_test) * 100\n",
        "\n",
        "# Evaluate Keras model\n",
        "_, keras_accuracy = model.evaluate(x_test_flat, y_test)\n",
        "\n",
        "print(\"Custom ANN Accuracy:\", custom_ann_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C0VUULbaOwr",
        "outputId": "18924d8d-e43f-4268-c0bf-61f34fa67867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras Accuracy: 96.79999947547913\n"
          ]
        }
      ],
      "source": [
        "print(\"Keras Accuracy:\", keras_accuracy*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB8VNfS7md8N"
      },
      "source": [
        "## As we can see, Custom ANN Accuracy \"97.06%\" And Keras ANN Accuracy-> \"96.73%\". Therefore my scratch ANN code have more accuracy then keras !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
